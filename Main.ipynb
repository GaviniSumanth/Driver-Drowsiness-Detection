{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Eye:\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "    def extractor_vid(frame: cv2.typing.MatLike):\n",
    "        left_eyes = []\n",
    "        right_eyes = []\n",
    "        image_gs = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = Eye.detector(image_gs)\n",
    "        for face in faces:\n",
    "            landmarks = Eye.predictor(image_gs, face)\n",
    "            # Left Eye\n",
    "            min_x, min_y, max_x, max_y = float(\"inf\"), float(\"inf\"), 0, 0\n",
    "            for n in range(36, 42):\n",
    "                x = landmarks.part(n).x\n",
    "                y = landmarks.part(n).y\n",
    "                min_x = min(min_x, x)\n",
    "                min_y = min(min_y, y)\n",
    "                max_x = max(max_x, x)\n",
    "                max_y = max(max_y, y)\n",
    "            left_eye = frame[min_y - 20 : max_y + 20, min_x - 20 : max_x + 20, :]\n",
    "            left_eyes.append(left_eye)\n",
    "\n",
    "            # Right Eye\n",
    "            min_x, min_y, max_x, max_y = float(\"inf\"), float(\"inf\"), 0, 0\n",
    "            for n in range(42, 48):\n",
    "                x = landmarks.part(n).x\n",
    "                y = landmarks.part(n).y\n",
    "                min_x = min(min_x, x)\n",
    "                min_y = min(min_y, y)\n",
    "                max_x = max(max_x, x)\n",
    "                max_y = max(max_y, y)\n",
    "            right_eye = frame[min_y - 20 : max_y + 20, min_x - 20 : max_x + 20, :]\n",
    "            right_eyes.append(right_eye)\n",
    "        return left_eyes, right_eyes\n",
    "\n",
    "    def extractor_img(image: np.ndarray):\n",
    "        eyes = Eye.extractor_vid(image)\n",
    "        eyes=[eyes[i][0] for i in range(len(eyes)) if len(eyes[i])>0]\n",
    "        return eyes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "class EyeClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EyeClassifier, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(16, 32, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(32, 64, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(64 * 8 * 8, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(-1, 64 * 8 * 8)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "model = EyeClassifier()\n",
    "model.load_state_dict(torch.load(\"eye_classifier.pth\"))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "EYE_COUNT = 30\n",
    "recent_predictions = collections.deque(maxlen=EYE_COUNT)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    eyes = Eye.extractor_img(frame)\n",
    "    for eye in eyes:\n",
    "        if eye.shape[-1] == 3 and eye.shape[0] > 0 and eye.shape[1] > 0 and eye.shape[2] > 0:\n",
    "            eye = cv2.resize(eye, (64, 64))\n",
    "            eye = torch.tensor(eye, dtype=torch.float32).permute(2, 0, 1).unsqueeze(0) / 255.0\n",
    "            pred = model(eye)\n",
    "            recent_predictions.append(pred.item())\n",
    "            avg_pred = sum(recent_predictions) / len(recent_predictions)\n",
    "            if avg_pred > 0.5:\n",
    "                cv2.putText(frame, \"Fatigue\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "            else:\n",
    "                cv2.putText(frame, \"Active\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow(\"Eye Classification\", frame)\n",
    "    if cv2.waitKey(1) == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
